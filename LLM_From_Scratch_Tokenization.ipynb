{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSCQ8RU/frqQV+ADMXLtYH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jgiet001-AI/LLM-From-Scrating-Learning/blob/main/LLM_From_Scratch_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o1sCT-jnWdN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"Copy of vsx.txt\"):\n",
        "  url = (\"https://raw.githubusercontent.com/Jgiet001-AI/LLM-from-scratch/refs/heads/main/Copy%20of%20vsx.txt\")\n",
        "  file_path = (\"Copy of vsx.txt\")\n",
        "  urllib.request.urlretrieve(url, file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"Copy of vsx.txt\", \"r\") as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "nXfEqs81tcZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnHG7_9ctqBg",
        "outputId": "9b1ab69c-3499-47ca-d67f-99f4c38e2930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126765"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, world. This is a test.\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RBtY7aIuChW",
        "outputId": "57c9facf-8cb8-48f5-f1ee-84125f7bc8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_Aho1BT6vU_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.]|\\s)', text)\n"
      ],
      "metadata": {
        "id": "dqKYz8W9u1Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GskqhZakvhl2",
        "outputId": "883a5701-2693-43e4-93bf-2a797d7d08ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySu6Wc_ivWLc",
        "outputId": "bbda75e8-e6e3-4025-bba7-abb6625a92c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result = re.findall(r'\\w+|[^\\w\\s]+', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym9OPXpYwcoA",
        "outputId": "57e0f1f3-45bc-4722-9a23-28a76248fa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "result: This is the variable where the output of the regex search will be stored. In this case, it's storing a list of all matches found in the text string.\n",
        "\n",
        "re.findall: The findall function from the re module searches the input string for all occurrences that match the provided regex pattern and returns them as a list.\n",
        "\n",
        "r'\\w+': This is the first part of the regex pattern. \\w represents any word character (alphanumeric or underscore), and + means \"one or more\" of the preceding token. So \\w+ matches one or more word characters in a row.\n",
        "\n",
        "|: This is the logical OR operator, which allows you to specify multiple regex patterns that should be considered valid matches. In this case, it separates the two different patterns that we want to match.\n",
        "\n",
        "[^\\w\\s]+: This is the second part of the regex pattern. The caret (^) inside the brackets negates the character class, meaning \"any character that is not in the following set.\" \\w represents any word character (alphanumeric or underscore), and \\s represents any whitespace character (space, tab, etc.). So [^\\w\\s]+ matches one or more characters that are neither alphanumeric nor a whitespace.\n",
        "\n",
        "text: This is the input string where the regex search is being performed. It should contain the text you want to analyze for matches.\n",
        "Putting it all together, this line of code searches the text string for all sequences of word characters (including underscores) or non-alphanumeric/whitespace characters. It returns them as a list stored in the variable result.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9HwPqMjKpVau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.findall(r'\\w+|[^\\w\\s]+', raw_text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "preprocessed = result\n"
      ],
      "metadata": {
        "id": "2cW-B7nuxoLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preprocessed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTJGTSrRyCka",
        "outputId": "5510a1bf-b87e-434e-fedd-2192776ef316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26539"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpqR9Qj7yfQq",
        "outputId": "d329e2fa-af7e-4a03-e346-af5728c52c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:Integer for Integer, token in enumerate(all_words)}\n",
        "#vocab"
      ],
      "metadata": {
        "id": "LUtITYQSzVAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s, i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.findall(r'\\w+|[^\\w\\s]+', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "    ids = [self.str_to_int [s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'([^\\s\\w])+', r'\\1', text)\n",
        "    return text\n",
        "\n",
        "#not GPT Tokenizer\n"
      ],
      "metadata": {
        "id": "j_Y-qyECl0cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token:Integer for Integer, token in enumerate(all_tokens)}\n"
      ],
      "metadata": {
        "id": "yjMNzY4OqxAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qPfQFAerl51",
        "outputId": "8e80748f-db9e-4ced-b21a-ed7cb4eecd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2453"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSXbH9KwsEAY",
        "outputId": "362cf46f-49f0-410b-c23e-1c729c7bb7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('■', 2448)\n",
            "('●', 2449)\n",
            "('\\ufeff', 2450)\n",
            "('<|endoftext|>', 2451)\n",
            "('<|unk|>', 2452)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F8xTyF87rlAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNo574RPsxN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s, i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.findall(r'\\w+|[^\\w\\s]+', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "    preprocessed = [\n",
        "        item if item in self.str_to_int\n",
        "        else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "\n",
        "    ids = [self.str_to_int [s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'([^\\s\\w])+', r'\\1', text)\n",
        "    return text\n",
        "\n",
        "#not GPT Tokenizer\n"
      ],
      "metadata": {
        "id": "N9l8KWrOtAFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)"
      ],
      "metadata": {
        "id": "LwyxjEWjuDVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98RSSyiOuUNh",
        "outputId": "2af17ff4-4800-4fa0-9c64-4ed94588150a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[544, 19, 2452, 26, 2452, 2276, 2452, 987, 2256, 2452]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the \"unk\"   token ('<|unk|>', 2452)"
      ],
      "metadata": {
        "id": "zaSo29tluqyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zqu_cS0ju_zx",
        "outputId": "bd006c9e-a6f7-4bd4-f261-69d2558582a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello , |unk> . |unk> this |unk> a test |unk>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDPOBgRaxj76",
        "outputId": "c0db05e2-c3df-44d1-d6ab-6ccc608b3d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte pair encoding\n",
        "Used by ChatGPT Llama"
      ],
      "metadata": {
        "id": "9DF-AFA2vnGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "xSlKcMdZviCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4dpZRPVwvZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}